# Slack Intelligence Documentation

Welcome to the Slack Intelligence tool documentation. This directory contains comprehensive guides for understanding, using, and extending the tool.

## üìö Documentation Index

### Getting Started

- **[PARQUET_CACHE_USAGE.md](PARQUET_CACHE_USAGE.md)** - Quick start guide for caching and querying Slack messages

### Architecture & Design

- **[CACHING_ARCHITECTURE.md](CACHING_ARCHITECTURE.md)** - Deep dive into the caching system architecture
- **[PARQUET_SCHEMA.md](PARQUET_SCHEMA.md)** - Complete schema specification for Slack messages and JIRA tickets
- **[IMPLEMENTATION_TREES.md](IMPLEMENTATION_TREES.md)** - Task trees and implementation planning
- **[SPIKE_SUMMARY.md](SPIKE_SUMMARY.md)** - Research spikes and exploration summaries

### Features

- **[JIRA_ENRICHMENT.md](JIRA_ENRICHMENT.md)** - ‚≠ê **NEW** BDD scenarios and implementation guide for JIRA ticket enrichment

---

## Feature: JIRA Enrichment

### Quick Overview

The JIRA enrichment feature allows you to:
- Extract JIRA ticket IDs from Slack messages automatically
- Fetch ticket metadata (status, priority, assignee, etc.) in parallel
- Cache tickets separately for efficient JOIN queries
- Correlate team discussions with ticket progress

### Usage

```bash
# Basic caching (no JIRA)
uv run slack-intel cache --days 7

# With JIRA enrichment
uv run slack-intel cache --enrich-jira --days 7

# Query messages with tickets
uv run slack-intel query -q "
  SELECT user_real_name, text, jira_tickets
  FROM 'cache/raw/messages/**/*.parquet'
  WHERE LENGTH(jira_tickets) > 0
"

# JOIN messages with JIRA metadata
uv run slack-intel query -q "
  SELECT m.text, j.summary, j.status
  FROM 'cache/raw/messages/**/*.parquet' m,
       UNNEST(m.jira_tickets) as ticket_id
  JOIN 'cache/raw/jira/**/*.parquet' j
    ON ticket_id = j.ticket_id
"
```

### BDD Scenarios Covered

See [JIRA_ENRICHMENT.md](JIRA_ENRICHMENT.md) for comprehensive BDD scenarios:

1. ‚úÖ **Basic JIRA Enrichment** - End-to-end pipeline
2. ‚úÖ **Ticket Extraction** - Regex-based extraction from message text
3. ‚úÖ **Parallel Fetching** - Batch fetching with rate limiting
4. ‚úÖ **Schema & Storage** - 28-field schema with nested structures
5. ‚úÖ **JOIN Queries** - DuckDB analytical queries
6. ‚úÖ **Error Handling** - Graceful degradation on failures
7. ‚úÖ **Opt-In Design** - No breaking changes to existing workflows
8. ‚úÖ **Date Partitioning** - Efficient date-based queries

### Implementation Surface Area

| Component | Files Changed | Lines Added |
|-----------|--------------|-------------|
| CLI Integration | `cli.py` | +185 |
| JIRA Schema & Caching | `parquet_cache.py` | +124 |
| Batch Fetching | `slack_channels.py` | +58 |
| Unit Tests | `test_parquet_cache.py` | +213 |
| Integration Tests | `test_integration.py` | +243 |
| **Total** | **5 files** | **+846 lines** |

### Test Coverage

- **Unit Tests:** 123/123 passing (9 JIRA-specific)
- **Integration Tests:** 2/4 passing (2 need JIRA API configuration)
- **Zero regressions** on existing functionality

---

## Configuration

### JIRA Setup

To enable JIRA enrichment, configure your JIRA instance:

**Option 1: Environment Variables**
```bash
export JIRA_EMAIL="your-email@company.com"
export JIRA_API_TOKEN="your-api-token"
```

**Option 2: Config File** (`.slack-intel.yaml`)
```yaml
jira:
  url: "https://your-domain.atlassian.net"
  # Credentials from environment
```

### Slack Setup

Configure Slack channels in `.slack-intel.yaml`:
```yaml
channels:
  - name: "engineering"
    id: "C9876543210"
  - name: "backend-devs"
    id: "C1234567890"
```

Or set environment variables:
```bash
export SLACK_BOT_TOKEN="xoxb-your-bot-token"
export SLACK_APP_TOKEN="xapp-your-app-token"
```

---

## Data Structure

### Cache Directory Layout

```
cache/raw/
‚îú‚îÄ‚îÄ messages/
‚îÇ   ‚îú‚îÄ‚îÄ dt=2025-10-19/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ channel=engineering/data.parquet
‚îÇ   ‚îî‚îÄ‚îÄ dt=2025-10-20/
‚îÇ       ‚îú‚îÄ‚îÄ channel=engineering/data.parquet
‚îÇ       ‚îú‚îÄ‚îÄ channel=backend-devs/data.parquet
‚îÇ       ‚îî‚îÄ‚îÄ channel=general/data.parquet
‚îÇ
‚îî‚îÄ‚îÄ jira/
    ‚îú‚îÄ‚îÄ dt=2025-10-19/data.parquet
    ‚îî‚îÄ‚îÄ dt=2025-10-20/data.parquet
```

### Message Schema (Parquet)

- **Core:** message_id, user_id, text, timestamp
- **Threads:** thread_ts, is_thread_parent, is_thread_reply, reply_count
- **User Info:** user_name, user_real_name, user_email, user_is_bot
- **Arrays:** reactions[], files[], jira_tickets[]
- **Flags:** has_reactions, has_files, has_thread

### JIRA Schema (Parquet)

- **Core:** ticket_id, summary, priority, issue_type, status, assignee
- **Timeline:** due_date, story_points, created, updated
- **Dependencies:** blocks[], blocked_by[], depends_on[], related[]
- **Components:** components[], labels[], fix_versions[]
- **Progress:** progress_total, progress_done, progress_percentage
- **Activity:** comments{}, total_comments, sprints[]
- **Metadata:** cached_at

---

## Query Examples

### Basic Queries

**Count messages by user:**
```sql
SELECT user_real_name, COUNT(*) as message_count
FROM 'cache/raw/messages/**/*.parquet'
GROUP BY user_real_name
ORDER BY message_count DESC
```

**Find messages with JIRA tickets:**
```sql
SELECT user_real_name, text, jira_tickets, dt
FROM 'cache/raw/messages/**/*.parquet'
WHERE LENGTH(jira_tickets) > 0
ORDER BY dt DESC
```

**Thread conversations:**
```sql
SELECT text, is_thread_parent, is_thread_reply, thread_ts
FROM 'cache/raw/messages/**/*.parquet'
WHERE thread_ts IS NOT NULL
ORDER BY thread_ts, timestamp
```

### Advanced JOIN Queries

**Messages with ticket status:**
```sql
SELECT
    m.user_real_name,
    m.text,
    j.ticket_id,
    j.summary,
    j.status,
    j.priority
FROM 'cache/raw/messages/**/*.parquet' m,
     UNNEST(m.jira_tickets) as ticket_id
JOIN 'cache/raw/jira/**/*.parquet' j
    ON ticket_id = j.ticket_id
WHERE j.status IN ('In Progress', 'Blocked')
```

**Aggregate by ticket status:**
```sql
SELECT
    j.status,
    j.priority,
    COUNT(DISTINCT m.message_id) as messages_mentioning,
    COUNT(DISTINCT j.ticket_id) as unique_tickets
FROM 'cache/raw/messages/**/*.parquet' m,
     UNNEST(m.jira_tickets) as ticket_id
LEFT JOIN 'cache/raw/jira/**/*.parquet' j
    ON ticket_id = j.ticket_id
GROUP BY j.status, j.priority
ORDER BY messages_mentioning DESC
```

**Blocked tickets discussion:**
```sql
SELECT
    m.user_real_name,
    m.text,
    j.ticket_id,
    j.summary,
    j.blocked_by,
    j.status
FROM 'cache/raw/messages/**/*.parquet' m,
     UNNEST(m.jira_tickets) as ticket_id
JOIN 'cache/raw/jira/**/*.parquet' j
    ON ticket_id = j.ticket_id
WHERE LENGTH(j.blocked_by) > 0
```

---

## Testing

### Run All Tests

```bash
# Unit tests only (fast)
uv run pytest tests/ -v -m "not integration"

# Integration tests (requires API credentials)
uv run pytest tests/ -v -m integration

# Specific test class
uv run pytest tests/test_parquet_cache.py::TestParquetCacheJiraTickets -v
```

### Test JIRA Enrichment

```bash
# Unit tests for JIRA caching
uv run pytest tests/test_parquet_cache.py::TestParquetCacheJiraTickets -v

# Integration test for batch fetching
uv run pytest tests/test_integration.py::TestJiraIntegration -v -m integration

# Full pipeline integration test
uv run pytest tests/test_integration.py::TestJiraEnrichmentIntegration -v -m integration
```

---

## Troubleshooting

### JIRA Enrichment Issues

**Problem:** "No JIRA tickets were successfully fetched"

**Solutions:**
1. Check JIRA domain in config: `https://your-domain.atlassian.net`
2. Verify environment variables: `JIRA_EMAIL`, `JIRA_API_TOKEN`
3. Test JIRA API manually: `curl -u email:token https://your-domain.atlassian.net/rest/api/2/issue/TICKET-123`
4. Check permissions: Ensure bot account can access tickets

**Problem:** "Rate limit exceeded"

**Solutions:**
1. Reduce concurrent requests (default: 10)
2. Add delays between batches
3. Check JIRA Cloud limits: ~100-300 req/min

**Problem:** "Some tickets return 404"

**Expected Behavior:**
- Individual ticket failures are logged as warnings
- Successfully fetched tickets are cached
- Message caching continues regardless
- This is graceful degradation by design

---

## Contributing

### Adding New Features

1. **Plan with BDD scenarios** - Document expected behavior first
2. **Write tests** - Unit tests for logic, integration for end-to-end
3. **Implement** - Follow existing patterns in codebase
4. **Document** - Add to relevant .md files in docs/
5. **Validate** - Ensure no regressions: `uv run pytest tests/ -v`

### Documentation Standards

- Use BDD (Given-When-Then) for feature scenarios
- Map scenarios to implementation surface area
- Include test coverage details
- Provide usage examples
- Link to relevant code sections with line numbers

---

## Version History

### v1.1.0 - JIRA Enrichment (2025-10-20)
- ‚ú® Added optional JIRA ticket metadata enrichment
- ‚ú® Parallel batch fetching with rate limiting
- ‚ú® 28-field JIRA schema with nested structures
- ‚ú® DuckDB JOIN query support
- üìù Comprehensive BDD documentation
- ‚úÖ 123/123 tests passing, zero regressions

### v1.0.0 - Initial Release
- üì¶ Parquet-based Slack message caching
- üßµ Thread reconstruction and analysis
- üìä DuckDB analytical queries
- üé® Rich CLI with progress tracking

---

## Resources

- **GitHub:** (Add your repo URL)
- **Issues:** (Add your issues URL)
- **Slack Community:** (Add if applicable)

For detailed implementation guides, see individual documentation files above.
